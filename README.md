# PulseMind-AI-Based-Realtime-Emotion-Detector
This is a multimodal AI detector which can be used to detect various emotions in realtime through audio as well as video and speech features 
This project uses 3 different AI models trained for emotion detection for videos,sound and speech expressions using various datasets available throughout the Internet.
Features of this AI is that all the parts are independent and can be used for specific purpouses and can also be fused to predict the results in realtime.

The project uses a fused output for 7 different categories of emotions which include Neutral,Happy,Sad,Angry,Disgust,Suprise and Fear and speech features such as pitch,tone,stress,pause ratio and then it is further finetuned to predict output via ChatBot Model Bert-Mini for four categories which include Positivity,Confidence,Engagement,Nervousness per frame in the video stream.

This project also contains a body gesture detection for face movements which can be integrated in future for more advance results.
Built for accuracy and adaptability, it can be integrated into diverse applicationsâ€”mental health support, customer experience optimization, education, workplace wellness, or human-computer interaction. The system bridges the gap between human feelings and technology, enabling more empathetic, personalized, and meaningful interactions.

